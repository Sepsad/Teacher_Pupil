{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials_Teacher = pd.read_csv(\"SS_trials_TEACH.csv\")\n",
    "data_trials_Teacher_learning = data_trials_Teacher[data_trials_Teacher.block_type == 'learning']\n",
    "data_trials_Teacher_testing = data_trials_Teacher[data_trials_Teacher.block_type == 'test']\n",
    "\n",
    "# del data_trials_Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_by_trial_type(df, n=None):\n",
    "\n",
    "    grouped_data = df.groupby('participant_id')\n",
    "\n",
    "    # Create empty lists to store results\n",
    "    participant_ids = []\n",
    "    trial_type_ids = []\n",
    "    accuracies = []\n",
    "    trial_numbers = []\n",
    "\n",
    "    # Iterate over each participant group\n",
    "    for participant_id, group in grouped_data:\n",
    "        # Group by trial_type_id within each participant\n",
    "        trial_type_groups = group.groupby('trial_type_id')\n",
    "        \n",
    "        # Calculate accuracy for each trial type\n",
    "        for trial_type_id, trial_group in trial_type_groups:\n",
    "            \n",
    "            trials_for_accuracy_calculation = trial_group # Default to all trials in the group\n",
    "            if n is not None and isinstance(n, int) and n > 0:\n",
    "                if not trial_group.empty:\n",
    "                    # Select the last n trials for accuracy calculation\n",
    "                    trials_for_accuracy_calculation = trial_group.tail(n)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            if not trials_for_accuracy_calculation.empty:\n",
    "                accuracy = trials_for_accuracy_calculation['accuracy'].mean()\n",
    "            else:\n",
    "                # If the group (or the tail) is empty, accuracy is undefined\n",
    "                accuracy = np.nan \n",
    "            \n",
    "            # trial_number still represents the total number of trials in this specific group\n",
    "            current_trial_number = trial_group.shape[0]\n",
    "            \n",
    "            # Append results\n",
    "            participant_ids.append(participant_id)\n",
    "            trial_type_ids.append(trial_type_id)\n",
    "            accuracies.append(accuracy)\n",
    "            trial_numbers.append(current_trial_number)\n",
    "\n",
    "    # Create DataFrame from results\n",
    "    accuracy_df = pd.DataFrame({\n",
    "        'participant_id': participant_ids,\n",
    "        'trial_type_id': trial_type_ids,\n",
    "        'accuracy': accuracies,\n",
    "        'trial_number': trial_numbers\n",
    "    })\n",
    "\n",
    "    return accuracy_df\n",
    "\n",
    "\n",
    "def calculate_learning_rate(df, window=None, by_trial_type=True):\n",
    "    if by_trial_type:\n",
    "        # Group by participant and trial type\n",
    "        grouped_data = df.groupby(['participant_id', 'trial_type_id'])\n",
    "    else:\n",
    "        # Group by participant only for overall learning\n",
    "        grouped_data = df.groupby(['participant_id'])\n",
    "    \n",
    "    # Create empty lists to store results\n",
    "    participant_ids = []\n",
    "    trial_type_ids = []\n",
    "    trial_numbers = []\n",
    "    cumulative_accuracies = []\n",
    "    \n",
    "    # Iterate over each group\n",
    "    for group_key, group in grouped_data:\n",
    "        # Handle different group keys based on grouping method\n",
    "        if by_trial_type:\n",
    "            participant_id, trial_type_id = group_key\n",
    "        else:\n",
    "            participant_id = group_key\n",
    "            trial_type_id = 'overall'  # Use 'overall' to indicate combined trial types\n",
    "        \n",
    "        # Calculate accuracy based on window parameter\n",
    "        if window is not None:\n",
    "            cumulative_accuracy = group['accuracy'].rolling(window=window, min_periods=1).mean()\n",
    "        else:\n",
    "            cumulative_accuracy = group['accuracy'].expanding().mean()\n",
    "        \n",
    "        # Append results\n",
    "        participant_ids.extend([participant_id] * len(group))\n",
    "        trial_type_ids.extend([trial_type_id] * len(group))\n",
    "        trial_numbers.extend(range(1, len(group) + 1))  # Generate sequential numbers\n",
    "        cumulative_accuracies.extend(cumulative_accuracy.tolist())\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    learning_df = pd.DataFrame({\n",
    "        'participant_id': participant_ids,\n",
    "        'trial_type_id': trial_type_ids,\n",
    "        'trial_number': trial_numbers,\n",
    "        'cumulative_accuracy': cumulative_accuracies,\n",
    "    })\n",
    "    \n",
    "    return learning_df\n",
    "\n",
    "def plot_learning_curves(df, title='Learning Curves by Trial Type'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Define the order of trial types\n",
    "    trial_types = ['plain', 'hatched', 'triangle']\n",
    "    \n",
    "    # Plot learning curves for each trial type\n",
    "    for trial_type in trial_types:\n",
    "        trial_data = df[df['trial_type_id'] == trial_type]\n",
    "        sns.lineplot(data=trial_data, x='trial_number', y='cumulative_accuracy',\n",
    "                    label=trial_type, errorbar='se')\n",
    "    \n",
    "    plt.xlabel('Trial Number')\n",
    "    plt.ylabel('Cumulative Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy_by_trial_type(df, title='Accuracy by Trial Type', cluster=False):\n",
    "    # Create a single figure\n",
    "    # Create a more elegant figure with better proportions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Use a cleaner style\n",
    "    with plt.style.context('seaborn-v0_8-whitegrid'):\n",
    "        # Set up the plot with a more descriptive title and custom font properties\n",
    "        plt.title(title, fontsize=16, fontweight='bold', pad=15)\n",
    "        \n",
    "        # Define the order of trial types\n",
    "        trial_types = ['plain', 'hatched', 'triangle']\n",
    "        \n",
    "        # Define a more elegant color palette\n",
    "        bar_color = '#8BBEE8'  # Soft blue\n",
    "        \n",
    "        # Create bar plot with error bars for all trial types\n",
    "        # print(df.mean())\n",
    "        ax = sns.barplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                    order=trial_types, errorbar='se', color=bar_color, alpha=0.6)\n",
    "        \n",
    "        # Add scatter points with jitter\n",
    "        if cluster:\n",
    "            # Use a more harmonious color palette for clusters\n",
    "            cluster_palette = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "            \n",
    "            sns.stripplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                        order=trial_types, hue='cluster', palette=cluster_palette, \n",
    "                        alpha=0.7, jitter=0.2, size=7, edgecolor='white', linewidth=0.5)\n",
    "            \n",
    "            # Improve legend appearance\n",
    "            plt.legend(title='Cluster', title_fontsize=12, fontsize=10, framealpha=0.9, \n",
    "                      edgecolor='lightgray', loc='upper right')\n",
    "        else:\n",
    "            sns.stripplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                        order=trial_types, color='#333333', alpha=0.6, \n",
    "                        jitter=0.2, size=7, edgecolor='white', linewidth=0.5)\n",
    "        \n",
    "        # Improve axis labels\n",
    "        plt.ylabel('Accuracy', fontsize=14, labelpad=10)\n",
    "        plt.xlabel('', fontsize=14, labelpad=10)\n",
    "        plt.ylim(0, 1.05)  # Set y-axis limits from 0 to 1\n",
    "        \n",
    "        # Customize tick parameters\n",
    "        plt.xticks(fontsize=16)  # Increased x tick label size\n",
    "        plt.yticks(fontsize=12)\n",
    "        \n",
    "        # Add subtle horizontal grid lines\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        # Rename x-tick labels to be more descriptive\n",
    "        ax.set_xticklabels([t.capitalize() for t in trial_types], fontsize=16)  # Increased font size here too\n",
    "        \n",
    "        # Remove top and right spines for cleaner look\n",
    "        sns.despine()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_accuracy_boxplots(df, title='Accuracy Boxplots by Trial Type', cluster=False):\n",
    "    # Create a single figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Add a more elegant title with better font\n",
    "    plt.title(title, fontsize=16, fontweight='medium', pad=15)\n",
    "\n",
    "    # Define the order of trial types\n",
    "    trial_types = ['plain', 'hatched', 'triangle']\n",
    "    \n",
    "    # Define a more elegant color palette\n",
    "    cluster_palette = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "    base_color = '#8BBEE8'  # Soft blue for non-clustered plots\n",
    "    \n",
    "    # Create box plots for trial types with improved styling\n",
    "    if cluster:\n",
    "        # Box plots with cluster as hue\n",
    "        sns.boxplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                   order=trial_types, hue='cluster', \n",
    "                   palette=cluster_palette,\n",
    "                   width=0.7, \n",
    "                   boxprops=dict(alpha=0.7, edgecolor='black', linewidth=0.8),\n",
    "                   whiskerprops=dict(linewidth=0.8),\n",
    "                   medianprops=dict(color='black', linewidth=1.5),\n",
    "                   capprops=dict(linewidth=0.8))\n",
    "        \n",
    "        # Improve legend appearance and place it outside the plot\n",
    "        plt.legend(title='Cluster', title_fontsize=12, fontsize=10, framealpha=0.9, \n",
    "                  edgecolor='lightgray', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    else:\n",
    "        # Box plots without cluster distinction\n",
    "        sns.boxplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                   order=trial_types, color=base_color,\n",
    "                   width=0.7, \n",
    "                   boxprops=dict(alpha=0.7, edgecolor='black', linewidth=0.8),\n",
    "                   whiskerprops=dict(linewidth=0.8),\n",
    "                   medianprops=dict(color='black', linewidth=1.5),\n",
    "                   capprops=dict(linewidth=0.8))\n",
    "    \n",
    "    # Add individual data points with jitter for better visualization\n",
    "    if cluster:\n",
    "        sns.stripplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                    order=trial_types, hue='cluster', palette=cluster_palette, \n",
    "                    dodge=True, alpha=0.7, jitter=0.2, size=5, \n",
    "                    edgecolor='white', linewidth=0.5, legend=False)\n",
    "    else:\n",
    "        sns.stripplot(data=df, x='trial_type_id', y='accuracy',\n",
    "                    order=trial_types, color='#333333', alpha=0.6, \n",
    "                    jitter=0.2, size=5, edgecolor='white', linewidth=0.5)\n",
    "    \n",
    "    # Improve axis labels\n",
    "    plt.ylabel('Accuracy', fontsize=14, labelpad=10)\n",
    "    plt.xlabel('', fontsize=14)  # Remove x-label as it's redundant\n",
    "    plt.ylim(0, 1.05)  # Set y-axis limits from 0 to 1\n",
    "    \n",
    "    # Customize tick parameters\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    # Add subtle horizontal grid lines\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Rename x-tick labels to be more descriptive\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels([t.capitalize() for t in trial_types], fontsize=12)\n",
    "    \n",
    "    # Remove top and right spines for cleaner look\n",
    "    sns.despine()\n",
    "    \n",
    "    # Adjust layout to make room for the legend\n",
    "    if cluster:\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_accuracy_by_cluster_and_trial_type(df, title='Accuracy by Cluster and Trial Type'):\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Define the order of trial types\n",
    "    trial_types = ['plain', 'hatched', 'triangle']\n",
    "    \n",
    "    # Define cluster colors\n",
    "    cluster_colors = {'Level0': 'blue', 'Level1': 'red', 'Level3': 'green'}\n",
    "    \n",
    "    # Create boxplots for each cluster within each trial type\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x='trial_type_id',\n",
    "        y='accuracy',\n",
    "        hue='cluster',\n",
    "        order=trial_types,\n",
    "        palette=cluster_colors,\n",
    "        width=0.7,\n",
    "        fliersize=3,\n",
    "        boxprops=dict(alpha=0.5),\n",
    "        medianprops=dict(color='black')\n",
    "    )\n",
    "    \n",
    "    # Add individual data points with jitter for better visualization\n",
    "    sns.stripplot(\n",
    "        data=df,\n",
    "        x='trial_type_id',\n",
    "        y='accuracy',\n",
    "        hue='cluster',\n",
    "        order=trial_types,\n",
    "        palette=cluster_colors,\n",
    "        dodge=True,\n",
    "        alpha=0.5,\n",
    "        jitter=0.2,\n",
    "        size=3,\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Improve legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend(handles[:3], labels[:3], title='Cluster', loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def perform_clustering(df, n_clusters=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform k-means clustering on accuracy data and return cluster assignments and centers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing accuracy data with columns ['hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "    n_clusters : int, default=3\n",
    "        Number of clusters for k-means\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (DataFrame with cluster assignments, cluster centers in original scale)\n",
    "    \"\"\"\n",
    "    # Prepare data for clustering\n",
    "    X = df[['hatched_acc', 'plain_acc', 'triangle_acc']]\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
    "    df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Get cluster centers in original scale\n",
    "    cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "    \n",
    "    # Print cluster centers\n",
    "    print(\"\\nCluster Centers (original scale):\")\n",
    "    for i, center in enumerate(cluster_centers):\n",
    "        print(f\"Cluster {i}:\")\n",
    "        print(f\"  Hatched accuracy: {center[0]:.3f}\")\n",
    "        print(f\"  Plain accuracy: {center[1]:.3f}\")\n",
    "        print(f\"  Triangle accuracy: {center[2]:.3f}\")\n",
    "    \n",
    "    # Print cluster sizes\n",
    "    print(\"\\nNumber of participants in each cluster:\")\n",
    "    print(df['cluster'].value_counts().sort_index())\n",
    "    \n",
    "    return df, cluster_centers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_gmm_clustering(df, n_components=3, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Mixture Model (GMM) clustering on accuracy data and return cluster assignments and means.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing accuracy data with columns ['hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "    n_components : int, default=3\n",
    "        Number of mixture components for GMM\n",
    "    random_state : int, default=42\n",
    "        Random state for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (DataFrame with cluster assignments, component means in original scale)\n",
    "    \"\"\"\n",
    "    # Prepare data for clustering\n",
    "    X = df[['hatched_acc', 'plain_acc', 'triangle_acc']]\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    # print(X_scaled)\n",
    "    \n",
    "    # Perform GMM clustering\n",
    "    # Make sure to import: from sklearn.mixture import GaussianMixture\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=random_state)\n",
    "    df['cluster'] = gmm.fit_predict(X_scaled)\n",
    "    \n",
    "    # Get component means in original scale\n",
    "    component_means_scaled = gmm.means_\n",
    "    component_means = scaler.inverse_transform(component_means_scaled)\n",
    "    \n",
    "    # Print component means\n",
    "    print(\"\\nComponent Means (original scale):\")\n",
    "    for i, mean_val in enumerate(component_means):\n",
    "        print(f\"Component {i}:\")\n",
    "        print(f\"  Hatched accuracy: {mean_val[0]:.3f}\")\n",
    "        print(f\"  Plain accuracy: {mean_val[1]:.3f}\")\n",
    "        print(f\"  Triangle accuracy: {mean_val[2]:.3f}\")\n",
    "\n",
    "    # Report BIC and AIC\n",
    "    bic = gmm.bic(X_scaled)\n",
    "    aic = gmm.aic(X_scaled)\n",
    "    \n",
    "    print(f\"\\nBIC: {bic:.3f}\")\n",
    "    print(f\"AIC: {aic:.3f}\")\n",
    "    \n",
    "    # Print cluster sizes\n",
    "    print(\"\\nNumber of participants in each cluster (component):\")\n",
    "    print(df['cluster'].value_counts().sort_index())\n",
    "    \n",
    "    return df, component_means\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_accuracy_df = calculate_accuracy_by_trial_type(data_trials_Teacher_learning, n=10)\n",
    "testing_accuracy_df = calculate_accuracy_by_trial_type(data_trials_Teacher_testing, n=10)\n",
    "teacher_overall_accuracy_df = calculate_accuracy_by_trial_type(data_trials_Teacher, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restructure learning_accuracy_df to have separate columns for each trial type accuracy\n",
    "learning_accuracy_df_restructured = learning_accuracy_df.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "learning_accuracy_df_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "\n",
    "\n",
    "# Display the restructured dataframe\n",
    "(learning_accuracy_df_restructured.head())\n",
    "\n",
    "\n",
    "testing_accuracy_df_restructured = testing_accuracy_df.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "testing_accuracy_df_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "# learning_accuracy_df_restructured, cluster_centers = perform_clustering(learning_accuracy_df_restructured, n_clusters=3)\n",
    "learning_accuracy_df_restructured, cluster_centers = perform_gmm_clustering(learning_accuracy_df_restructured, n_components=3)\n",
    "learning_acc_with_cluster = learning_accuracy_df.merge(\n",
    "    learning_accuracy_df_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {0: 'Level1', 1: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "learning_acc_with_cluster['cluster'] = learning_acc_with_cluster['cluster'].map(cluster_mapping)\n",
    "learning_accuracy_df_restructured['cluster'] = learning_accuracy_df_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "# learning_accuracy_df_restructured, cluster_centers = perform_clustering(learning_accuracy_df_restructured, n_clusters=3)\n",
    "testing_accuracy_df_restructured, cluster_centers = perform_clustering(testing_accuracy_df_restructured, n_clusters=3)\n",
    "testing_acc_with_cluster = testing_accuracy_df.merge(\n",
    "    testing_accuracy_df_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {0: 'Level1', 1: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "testing_acc_with_cluster['cluster'] = testing_acc_with_cluster['cluster'].map(cluster_mapping)\n",
    "testing_accuracy_df_restructured['cluster'] = testing_accuracy_df_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "# learning_accuracy_df_restructured, cluster_centers = perform_clustering(learning_accuracy_df_restructured, n_clusters=3)\n",
    "learning_accuracy_df_restructured, cluster_centers = perform_gmm_clustering(learning_accuracy_df_restructured, n_components=3)\n",
    "learning_acc_with_cluster = learning_accuracy_df.merge(\n",
    "    learning_accuracy_df_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {0: 'Level1', 1: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "learning_acc_with_cluster['cluster'] = learning_acc_with_cluster['cluster'].map(cluster_mapping)\n",
    "learning_accuracy_df_restructured['cluster'] = learning_accuracy_df_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def silhouette_analysis_gmm(data, max_clusters=10, perform_gmm_clustering=None, mode='kmeans'):\n",
    "    \"\"\"\n",
    "    Perform silhouette analysis for GMM or K-means clustering\n",
    "    \n",
    "    Parameters:\n",
    "    data: your dataset\n",
    "    max_clusters: maximum number of clusters to test\n",
    "    perform_gmm_clustering: your custom GMM function (optional)\n",
    "    mode: clustering algorithm to use ('gmm' or 'kmeans')\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster_range = range(2, max_clusters + 1)\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for n_clusters in cluster_range:\n",
    "        if perform_gmm_clustering is not None:\n",
    "            # Use your custom function\n",
    "            labels = perform_gmm_clustering(data, n_clusters)\n",
    "        else:\n",
    "            # Use standard GMM or KMeans based on mode\n",
    "            if mode.lower() == 'gmm':\n",
    "                model = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "                labels = model.fit_predict(data)\n",
    "            elif mode.lower() == 'kmeans':\n",
    "                model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "                labels = model.fit_predict(data)\n",
    "            else:\n",
    "                raise ValueError(\"Mode must be either 'gmm' or 'kmeans'\")\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        score = silhouette_score(data, labels)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f\"For {n_clusters} clusters, silhouette score = {score:.3f}\")\n",
    "    \n",
    "    # Plot the results with a white background\n",
    "    plt.figure(figsize=(10, 6), facecolor='white')\n",
    "    \n",
    "    # Create a white background\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('white')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color('#555555')\n",
    "    ax.spines['bottom'].set_color('#555555')\n",
    "    \n",
    "    # Plot silhouette scores with a more elegant style\n",
    "    plt.plot(cluster_range, silhouette_scores, marker='o', markersize=10, \n",
    "             linewidth=2.5, color='#3498db', markerfacecolor='white', \n",
    "             markeredgecolor='#3498db', markeredgewidth=2)\n",
    "    \n",
    "    # Add subtle grid only on y-axis\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.3, color='#cccccc')\n",
    "    \n",
    "    # Highlight the best score with a more elegant indicator\n",
    "    best_k = cluster_range[np.argmax(silhouette_scores)]\n",
    "    best_score = max(silhouette_scores)\n",
    "    plt.axvline(x=best_k, color='#e74c3c', linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "    \n",
    "    # Add annotation for best score with a subtle background\n",
    "    bbox_props = dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=\"#e74c3c\", alpha=0.9)\n",
    "    plt.text(best_k + 0.15, best_score - 0.02, f'Optimal: {best_k} clusters\\n(score: {best_score:.3f})', \n",
    "             ha='left', va='top', fontsize=11, color='#333333', \n",
    "             bbox=bbox_props)\n",
    "    \n",
    "    # Enhance labels and title\n",
    "    plt.xlabel('Number of Clusters', fontsize=12, color='#333333', fontweight='bold')\n",
    "    plt.ylabel('Silhouette Score', fontsize=12, color='#333333', fontweight='bold')\n",
    "    plt.title(f'Silhouette Analysis for Optimal {mode.upper()} Clustering', \n",
    "              fontsize=14, color='#333333', fontweight='bold', pad=15)\n",
    "    \n",
    "    # Improve tick parameters\n",
    "    plt.tick_params(axis='both', colors='#555555', direction='out', length=6, width=1)\n",
    "    plt.xticks(cluster_range)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cluster_range, silhouette_scores, best_k\n",
    "\n",
    "\n",
    "\n",
    "# Or without your custom function:\n",
    "cluster_range, scores, best_k = silhouette_analysis_gmm(learning_accuracy_df_restructured[['hatched_acc', 'plain_acc', 'triangle_acc']], max_clusters=6)\n",
    "# cluster_range, scores, best_k = silhouette_analysis_gmm(testing_accuracy_df_restructured[['hatched_acc', 'plain_acc', 'triangle_acc']], max_clusters=8, mode='kmeans')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_acc_with_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_acc_with_cluster[['trial_type_id', 'accuracy']].groupby('trial_type_id')['accuracy'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_by_trial_type(learning_acc_with_cluster, 'Learning Accuracy - Teacher', cluster=False)\n",
    "plot_accuracy_by_trial_type(testing_accuracy_df, 'Test Accuracy - Teacher', cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with appropriate size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Define color palette for clusters\n",
    "cluster_colors = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "\n",
    "# Compute summary statistics for each trial type\n",
    "trial_type_order = ['plain', 'hatched', 'triangle']\n",
    "trial_type_data = learning_acc_with_cluster.groupby(['trial_type_id', 'cluster'])['accuracy'].agg(['mean', 'sem']).reset_index()\n",
    "\n",
    "# Reorder trial_type_data to have plain first, hatched second, triangle third\n",
    "trial_type_order = ['plain', 'hatched', 'triangle']\n",
    "trial_type_data = trial_type_data.sort_values('trial_type_id', key=lambda x: x.map({t: i for i, t in enumerate(trial_type_order)}))\n",
    "trial_type_data = trial_type_data.reset_index(drop=True)\n",
    "\n",
    "# Create grouped bar chart\n",
    "# Set positions for the bars\n",
    "bar_width = 0.25\n",
    "r1 = np.arange(len(trial_type_order))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "\n",
    "# Filter data for each cluster\n",
    "level0 = trial_type_data[trial_type_data['cluster'] == 'Level0']\n",
    "level1 = trial_type_data[trial_type_data['cluster'] == 'Level1']\n",
    "level3 = trial_type_data[trial_type_data['cluster'] == 'Level3']\n",
    "\n",
    "# Create bar plots for each cluster\n",
    "# Create bar plots for each cluster\n",
    "plt.bar(r1, level0['mean'], \n",
    "    width=bar_width, color=cluster_colors['Level0'], label='Level0', \n",
    "    yerr=level0['sem'],\n",
    "    capsize=5, alpha=0.8, edgecolor='black', linewidth=0.8)\n",
    "\n",
    "plt.bar(r2, level1['mean'], \n",
    "    width=bar_width, color=cluster_colors['Level1'], label='Level1', \n",
    "    yerr=level1['sem'],\n",
    "    capsize=5, alpha=0.8, edgecolor='black', linewidth=0.8)\n",
    "\n",
    "plt.bar(r3, level3['mean'], \n",
    "    width=bar_width, color=cluster_colors['Level3'], label='Level3', \n",
    "    yerr=level3['sem'],\n",
    "    capsize=5, alpha=0.8, edgecolor='black', linewidth=0.8)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Cluster', fontsize=12, title_fontsize=14, \n",
    "       loc='upper right', framealpha=0.9)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Teachers Performance by Trial Type and Cluster', fontsize=18, pad=15)\n",
    "plt.xlabel('Trial Type', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Performance', fontsize=14, labelpad=10)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Improve xticks\n",
    "plt.xticks([r + bar_width for r in range(len(trial_type_order))], \n",
    "       [t.capitalize() for t in trial_type_order], fontsize=12)\n",
    "\n",
    "# Improve legend\n",
    "# Create a more elegant legend placed outside the figure\n",
    "plt.legend(title='Cluster', fontsize=12, title_fontsize=14, \n",
    "           bbox_to_anchor=(1.05, 1), loc='upper left', framealpha=0.9)\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_type_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_accuracy_boxplots(learning_acc_with_cluster, 'Learning Accuracy by Trial Type Teacher', cluster=True)\n",
    "plot_accuracy_barplots(learning_acc_with_cluster, 'Learning Accuracy by Trial Type Teacher', cluster=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_boxplots(testing_acc_with_cluster, 'Testing Accuracy by Trial Type Teacher', cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_accuracy_df_restructured = testing_accuracy_df.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "testing_accuracy_df_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "\n",
    "# Display the restructured dataframe\n",
    "(testing_accuracy_df_restructured.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "testing_accuracy_df_restructured, cluster_centers = perform_clustering(testing_accuracy_df_restructured)\n",
    "testing_acc_with_cluster = testing_accuracy_df.merge(\n",
    "    testing_accuracy_df_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {0: 'Level1', 1: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "testing_acc_with_cluster['cluster'] = testing_acc_with_cluster['cluster'].map(cluster_mapping)\n",
    "testing_accuracy_df_restructured['cluster'] = testing_accuracy_df_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_df = calculate_learning_rate(data_trials_Teacher_learning, window=20)\n",
    "plot_learning_curves(learning_rate_df, 'Learning Curves by Trial Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials_Pupil = pd.read_csv(\"SS_trials_Pupil.csv\")\n",
    "pupil_participants = pd.read_csv(\"SS_participants_Pupil.csv\")\n",
    "data_trials_Pupil = data_trials_Pupil[data_trials_Pupil.participant_id.isin(pupil_participants.id)]\n",
    "data_trials_Pupil_learning = data_trials_Pupil[data_trials_Pupil.block_type == 'learning']\n",
    "data_trials_Pupil_testing = data_trials_Pupil[data_trials_Pupil.block_type == 'test']\n",
    "\n",
    "del data_trials_Pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_accuracy_df_Pupil = calculate_accuracy_by_trial_type(data_trials_Pupil_learning)\n",
    "testing_accuracy_df_Pupil = calculate_accuracy_by_trial_type(data_trials_Pupil_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "testing_accuracy_df_Pupil_restructured = testing_accuracy_df_Pupil.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "testing_accuracy_df_Pupil_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "\n",
    "testing_accuracy_df_Pupil_restructured, cluster_centers = perform_gmm_clustering(testing_accuracy_df_Pupil_restructured, n_components=3)\n",
    "# testing_accuracy_df_Pupil_restructured, cluster_centers = perform_clustering(testing_accuracy_df_Pupil_restructured, n_clusters=3)\n",
    "\n",
    "testing_acc_Pupil_with_cluster = testing_accuracy_df_Pupil.merge(\n",
    "    testing_accuracy_df_Pupil_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {2: 'Level1', 0: 'Level3', 1: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "testing_acc_Pupil_with_cluster['cluster'] = testing_acc_Pupil_with_cluster['cluster'].map(cluster_mapping)\n",
    "testing_accuracy_df_Pupil_restructured['cluster'] = testing_accuracy_df_Pupil_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_accuracy_df_Pupil = calculate_accuracy_by_trial_type(data_trials_Pupil_learning)\n",
    "# plot_accuracy_by_trial_type(testing_acc_Pupil_with_cluster, 'Testing Accuracy by Trial Type Pupil', cluster=True)\n",
    "plot_accuracy_boxplots(testing_acc_Pupil_with_cluster, 'Testing Accuracy by Trial Type Pupil', cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "learning_accuracy_df_Pupil_restructured = learning_accuracy_df_Pupil.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "learning_accuracy_df_Pupil_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "\n",
    "learning_accuracy_df_Pupil_restructured, cluster_centers = perform_gmm_clustering(learning_accuracy_df_Pupil_restructured, n_components=3)\n",
    "# learning_accuracy_df_Pupil_restructured, cluster_centers = perform_clustering(learning_accuracy_df_Pupil_restructured, n_clusters=3)\n",
    "\n",
    "learning_acc_Pupil_with_cluster = learning_accuracy_df_Pupil.merge(\n",
    "    learning_accuracy_df_Pupil_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {1: 'Level1', 0: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "learning_acc_Pupil_with_cluster['cluster'] = learning_acc_Pupil_with_cluster['cluster'].map(cluster_mapping)\n",
    "learning_accuracy_df_Pupil_restructured['cluster'] = learning_accuracy_df_Pupil_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy_boxplots(learning_acc_Pupil_with_cluster, 'Learning Accuracy by Trial Type Pupil', cluster=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_clusters = testing_acc_Pupil_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "teacher_clusters = testing_acc_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "pupil_teacher_relation = pupil_participants[['id', 'teacher_participant_id']]\n",
    "\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_relation, pupil_clusters, left_on='id', right_on='participant_id', how='left')\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_clusters, teacher_clusters, left_on='teacher_participant_id', right_on='participant_id', suffixes=('_pupil', '_teacher'), how='left')\n",
    "pupil_teacher_clusters = pupil_teacher_clusters[['id', 'teacher_participant_id', 'cluster_pupil', 'cluster_teacher']]\n",
    "pupil_teacher_clusters = pupil_teacher_clusters.dropna(subset=['cluster_pupil', 'cluster_teacher'])\n",
    "\n",
    "\n",
    "# pupil_teacher_clusters\n",
    "\n",
    "\n",
    "# Create normalized confusion matrix\n",
    "cluster_flow_norm = pd.crosstab(pupil_teacher_clusters['cluster_teacher'], \n",
    "                                pupil_teacher_clusters['cluster_pupil'], \n",
    "                                normalize='index')\n",
    "\n",
    "# Plot normalized heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cluster_flow_norm, annot=True, fmt='.001%', cmap='Blues', \n",
    "            annot_kws={'size': 20, 'weight': 'bold'},\n",
    "            cbar_kws={'label': 'Proportion of Pupils', })\n",
    "plt.xlabel('Pupil Cluster', size=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "plt.ylabel('Teacher Cluster', size=20)\n",
    "plt.title('Before Learning', size=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_clusters = learning_acc_Pupil_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "teacher_clusters = testing_acc_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "pupil_teacher_relation = pupil_participants[['id', 'teacher_participant_id']]\n",
    "\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_relation, pupil_clusters, left_on='id', right_on='participant_id', how='left')\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_clusters, teacher_clusters, left_on='teacher_participant_id', right_on='participant_id', suffixes=('_pupil', '_teacher'), how='left')\n",
    "pupil_teacher_clusters = pupil_teacher_clusters[['id', 'teacher_participant_id', 'cluster_pupil', 'cluster_teacher']]\n",
    "pupil_teacher_clusters = pupil_teacher_clusters.dropna(subset=['cluster_pupil', 'cluster_teacher'])\n",
    "\n",
    "\n",
    "# pupil_teacher_clusters\n",
    "\n",
    "# Create a crosstab for teacher cluster vs pupil cluster\n",
    "cluster_flow_norm = pd.crosstab(pupil_teacher_clusters['cluster_teacher'], \n",
    "                                pupil_teacher_clusters['cluster_pupil'], \n",
    "                                normalize='index')\n",
    "\n",
    "# Plot normalized heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cluster_flow_norm, annot=True, fmt='.001%', cmap='Blues', \n",
    "            annot_kws={'size': 20, 'weight': 'bold'},\n",
    "            cbar_kws={'label': 'Proportion of Pupils', })\n",
    "plt.xlabel('Pupil Cluster', size=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.yticks(rotation=0, fontsize=12)\n",
    "plt.ylabel('', size=20)\n",
    "plt.title('After Learning', size=18)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster information to the original learning_accuracy_df\n",
    "\n",
    "learning_accuracy_df_Pupil_restructured = learning_accuracy_df_Pupil.pivot(\n",
    "    index='participant_id',\n",
    "    columns='trial_type_id',\n",
    "    values='accuracy'\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns to be more descriptive\n",
    "learning_accuracy_df_Pupil_restructured.columns = ['participant_id', 'hatched_acc', 'plain_acc', 'triangle_acc']\n",
    "\n",
    "learning_accuracy_df_Pupil_restructured, cluster_centers = perform_clustering(learning_accuracy_df_Pupil_restructured)\n",
    "learning_acc_Pupil_with_cluster = learning_accuracy_df_Pupil.merge(\n",
    "    learning_accuracy_df_Pupil_restructured[['participant_id', 'cluster']],\n",
    "    on='participant_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Create a mapping dictionary for cluster renaming\n",
    "cluster_mapping = {1: 'Level1', 0: 'Level3', 2: 'Level0'}\n",
    "\n",
    "# Apply the mapping to rename clusters\n",
    "learning_acc_Pupil_with_cluster['cluster'] = learning_acc_Pupil_with_cluster['cluster'].map(cluster_mapping)\n",
    "learning_accuracy_df_Pupil_restructured['cluster'] = learning_accuracy_df_Pupil_restructured['cluster'].map(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_accuracy_df_Pupil = calculate_accuracy_by_trial_type(data_trials_Pupil_learning)\n",
    "# plot_accuracy_by_trial_type(learning_acc_Pupil_with_cluster, 'Learning Accuracy by Trial Type Pupil', cluster=True)\n",
    "plot_accuracy_boxplots(learning_acc_Pupil_with_cluster, 'Learning Accuracy by Trial Type Pupil', cluster=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_accuracy_by_cluster_and_trial_type(learning_acc_Pupil_with_cluster, 'Accuracy Pupil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pupil_learning_rate_df = calculate_learning_rate(data_trials_Pupil_testing)\n",
    "plot_learning_curves(Pupil_learning_rate_df[Pupil_learning_rate_df.participant_id != 62], 'Testing Type Pupil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pupil_learning_rate_df = calculate_learning_rate(data_trials_Pupil_learning, window=15, by_trial_type=False)\n",
    "# plot_learning_curves(Pupil_learning_rate_df[Pupil_learning_rate_df.participant_id != 62], 'Learning Curves by Trial Type Pupil')\n",
    "Pupil_learning_rate_df = Pupil_learning_rate_df[Pupil_learning_rate_df.participant_id != (62,)]\n",
    "\n",
    "teacher_learning_rate_df = calculate_learning_rate(data_trials_Teacher_learning, window=15, by_trial_type=False)\n",
    "teacher_learning_rate_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pupil_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of trials per participant and trial type\n",
    "trial_counts = data_trials_Pupil_learning.groupby(['participant_id', 'trial_type_id']).size().reset_index(name='trial_count')\n",
    "\n",
    "# Create pivot table to show trials per participant by trial type\n",
    "trial_counts_pivot = trial_counts.pivot(index='participant_id', columns='trial_type_id', values='trial_count').fillna(0)\n",
    "\n",
    "trial_counts_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trials_Pupil_learning = data_trials_Pupil_learning[data_trials_Pupil_learning.participant_id != 62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate learning rates for both Teacher and Pupil learning data\n",
    "teacher_learning_rate = calculate_learning_rate(data_trials_Teacher_learning, window=5, by_trial_type=False)\n",
    "\n",
    "pupil_learning_rate = calculate_learning_rate(data_trials_Pupil_learning, \n",
    "                                              window=5, by_trial_type=False)\n",
    "pupil_test_learning_rate = calculate_learning_rate(data_trials_Pupil_testing, \n",
    "                                              window=5, by_trial_type=False)\n",
    "\n",
    "# Add identifier columns\n",
    "teacher_learning_rate['type'] = 'Teacher'\n",
    "pupil_learning_rate['type'] = 'Pupil_w/_feedback'\n",
    "pupil_test_learning_rate['type'] = 'Pupil_w/o_feedback'\n",
    "\n",
    "\n",
    "\n",
    "pupil_learning_rate_filtered = pupil_learning_rate[pupil_learning_rate['trial_number'] <= 60]\n",
    "pupil_test_learning_rate = pupil_test_learning_rate[pupil_test_learning_rate['trial_number'] <= 30]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine dataframes\n",
    "combined_learning_rate = pd.concat([teacher_learning_rate])\n",
    "# combined_learning_rate = pd.concat([pupil_learning_rate_filtered])\n",
    "# combined_learning_rate = pd.concat([pupil_test_learning_rate ])\n",
    "\n",
    "\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot learning curves\n",
    "sns.lineplot(\n",
    "    data=combined_learning_rate, \n",
    "    x='trial_number', \n",
    "    y='cumulative_accuracy', \n",
    "    hue='type',\n",
    "    errorbar='se',\n",
    "    palette={'Teacher': '#3A6B9F', 'Pupil_w/_feedback': '#E3675C', 'Pupil_w/o_feedback': \"#E3675C\"},\n",
    "    linewidth=3\n",
    ")\n",
    "\n",
    "# Add horizontal line at 0.5 (chance level)\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Chance level')\n",
    "\n",
    "# Enhance the plot appearance\n",
    "plt.title('', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel('Trial Number', fontsize=14)\n",
    "plt.ylabel('Cumulative Accuracy', fontsize=14)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Improve legend\n",
    "plt.legend(title='Participant Type', title_fontsize=12, fontsize=12, framealpha=0.9)\n",
    "\n",
    "# Create custom x-ticks that show 30-90 instead of 0-60\n",
    "# new_ticks = np.arange(30, 91, 10)  # [30, 40, 50, 60, 70, 80, 90]\n",
    "# plt.xticks(np.arange(0, 61, 10), new_ticks)  #\n",
    "\n",
    "\n",
    "# new_ticks = np.arange(0, 31, 10)  # [10, 20, 30]\n",
    "# plt.xticks(np.arange(0, 31, 10), new_ticks)  #\n",
    "\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_learning_rate = pd.concat([pupil_test_learning_rate ])\n",
    "combined_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_test_learning_rate['type'] = 'Pupil_Test'\n",
    "pupil_test_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract participant IDs properly from string tuples or integers\n",
    "# First convert to string to handle all types safely\n",
    "teacher_learning_rate['participant_id_clean'] = teacher_learning_rate['participant_id'].astype(str)\n",
    "# Now strip parentheses and commas\n",
    "teacher_learning_rate['participant_id_clean'] = teacher_learning_rate['participant_id_clean'].str.strip('()').str.replace(',', '')\n",
    "# Convert to integer, only for values that can be converted\n",
    "teacher_learning_rate['participant_id_clean'] = pd.to_numeric(teacher_learning_rate['participant_id_clean'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get teacher cluster information and merge with learning rate data\n",
    "teacher_learning_with_cluster = teacher_learning_rate.merge(\n",
    "    teacher_clusters, \n",
    "    left_on=teacher_learning_rate['participant_id_clean'].astype(int),\n",
    "    right_on='participant_id',\n",
    "    how='left'\n",
    ").dropna(subset=['cluster'])\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Define cluster colors\n",
    "cluster_colors = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "\n",
    "# Plot learning curves for each cluster\n",
    "for cluster in ['Level0', 'Level1', 'Level3']:\n",
    "    cluster_data = teacher_learning_with_cluster[teacher_learning_with_cluster['cluster'] == cluster]\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=cluster_data,\n",
    "        x='trial_number',\n",
    "        y='cumulative_accuracy',\n",
    "        color=cluster_colors[cluster],\n",
    "        label=f'{cluster}',\n",
    "        errorbar='se',\n",
    "        linewidth=3\n",
    "    )\n",
    "\n",
    "# Add horizontal line at chance level\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Chance level')\n",
    "\n",
    "# Enhance plot appearance\n",
    "plt.title('', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel('Trial Number', fontsize=14)\n",
    "plt.ylabel('Cumulative Accuracy', fontsize=14)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Improve legend\n",
    "# plt.legend(title='Performance Cluster', title_fontsize=12, fontsize=12, framealpha=0.9)\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot for pupil clusters in testing\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Define color palette for clusters\n",
    "cluster_colors = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "\n",
    "# Get unique clusters\n",
    "clusters = testing_acc_Pupil_with_cluster['cluster'].unique()\n",
    "\n",
    "# Calculate learning curves for each cluster\n",
    "for cluster in clusters:\n",
    "    # Filter data for this cluster\n",
    "    cluster_data = data_trials_Pupil_testing[data_trials_Pupil_testing['participant_id'].isin(\n",
    "        testing_acc_Pupil_with_cluster[testing_acc_Pupil_with_cluster['cluster'] == cluster]['participant_id']\n",
    "    )]\n",
    "    \n",
    "    # Calculate learning rate for this cluster\n",
    "    cluster_learning_rate = calculate_learning_rate(cluster_data, window=10, by_trial_type=False)\n",
    "    \n",
    "    # Filter to show only first 60 trials\n",
    "    cluster_learning_rate = cluster_learning_rate[cluster_learning_rate['trial_number'] <= 30]\n",
    "\n",
    "    \n",
    "    # Add cluster identifier\n",
    "    cluster_learning_rate['cluster'] = cluster\n",
    "    \n",
    "    # Plot learning curve for this cluster\n",
    "    sns.lineplot(\n",
    "        data=cluster_learning_rate,\n",
    "        x='trial_number',\n",
    "        y='cumulative_accuracy',\n",
    "        color=cluster_colors[cluster],\n",
    "        label=f'{cluster}',\n",
    "        errorbar='se',\n",
    "        linewidth=3\n",
    "    )\n",
    "\n",
    "# Add horizontal line at chance level\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Chance level')\n",
    "\n",
    "# Enhance plot appearance\n",
    "plt.title('', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel('Trial Number', fontsize=14)\n",
    "plt.ylabel('Cumulative Accuracy', fontsize=14)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Improve legend\n",
    "# plt.legend(title='Performance Cluster', title_fontsize=12, fontsize=12, framealpha=0.9)\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot for pupil clusters in learning\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Define color palette for clusters\n",
    "cluster_colors = {'Level0': '#3A6B9F', 'Level1': '#E3675C', 'Level3': '#4CAF50'}\n",
    "\n",
    "# Get unique clusters\n",
    "clusters = learning_acc_Pupil_with_cluster['cluster'].unique()\n",
    "\n",
    "# Calculate learning curves for each cluster\n",
    "for cluster in clusters:\n",
    "    # Filter data for this cluster\n",
    "    cluster_data = data_trials_Pupil_learning[data_trials_Pupil_learning['participant_id'].isin(\n",
    "        learning_acc_Pupil_with_cluster[learning_acc_Pupil_with_cluster['cluster'] == cluster]['participant_id']\n",
    "    )]\n",
    "    \n",
    "    # Calculate learning rate for this cluster\n",
    "    cluster_learning_rate = calculate_learning_rate(cluster_data, window=10, by_trial_type=False)\n",
    "    \n",
    "    # Filter to show only first 60 trials\n",
    "    cluster_learning_rate = cluster_learning_rate[cluster_learning_rate['trial_number'] <= 60]\n",
    "\n",
    "    \n",
    "    # Add cluster identifier\n",
    "    cluster_learning_rate['cluster'] = cluster\n",
    "    \n",
    "    # Plot learning curve for this cluster\n",
    "    sns.lineplot(\n",
    "        data=cluster_learning_rate,\n",
    "        x='trial_number',\n",
    "        y='cumulative_accuracy',\n",
    "        color=cluster_colors[cluster],\n",
    "        label=f'{cluster}',\n",
    "        errorbar='se',\n",
    "        linewidth=3\n",
    "    )\n",
    "\n",
    "# Add horizontal line at chance level\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Chance level')\n",
    "\n",
    "# Enhance plot appearance\n",
    "plt.title('', fontsize=18, fontweight='bold', pad=15)\n",
    "plt.xlabel('Trial Number', fontsize=14)\n",
    "plt.ylabel('Cumulative Accuracy', fontsize=14)\n",
    "plt.ylim(0.4, 1.0)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Improve legend\n",
    "# plt.legend(title='Performance Cluster', title_fontsize=12, fontsize=12, framealpha=0.9)\n",
    "\n",
    "# Remove top and right spines\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_learning_rate_df['type'] = 'teacher'\n",
    "Pupil_learning_rate_df['type'] = 'pupil'\n",
    "\n",
    "# concatenate the two dataframes\n",
    "learning_rate_avg = pd.concat([teacher_learning_rate_df, Pupil_learning_rate_df])\n",
    "\n",
    "# Display the averaged learning rate dataframe\n",
    "\n",
    "# plot and compare the two learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=learning_rate_avg, x='trial_number', y='cumulative_accuracy', hue='type', errorbar='se', marker='')\n",
    "plt.title('Learning Curves', fontsize=16)\n",
    "plt.xlabel('Trial Number', fontsize=14)\n",
    "plt.ylabel('Average Cumulative Accuracy', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupil_clusters = learning_acc_Pupil_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "teacher_clusters = learning_acc_with_cluster[['participant_id', 'cluster']].drop_duplicates().reset_index(drop=True)\n",
    "pupil_teacher_relation = pupil_participants[['id', 'teacher_participant_id']]\n",
    "\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_relation, pupil_clusters, left_on='id', right_on='participant_id', how='left')\n",
    "pupil_teacher_clusters = pd.merge(pupil_teacher_clusters, teacher_clusters, left_on='teacher_participant_id', right_on='participant_id', suffixes=('_pupil', '_teacher'), how='left')\n",
    "pupil_teacher_clusters = pupil_teacher_clusters[['id', 'teacher_participant_id', 'cluster_pupil', 'cluster_teacher']]\n",
    "pupil_teacher_clusters = pupil_teacher_clusters.dropna(subset=['cluster_pupil', 'cluster_teacher'])\n",
    "\n",
    "\n",
    "pupil_teacher_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab for teacher cluster vs pupil cluster\n",
    "cluster_flow = pd.crosstab(pupil_teacher_clusters['cluster_teacher'], pupil_teacher_clusters['cluster_pupil'])\n",
    "\n",
    "# Plot as heatmap\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cluster_flow, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Pupil Cluster')\n",
    "plt.ylabel('Teacher Cluster')\n",
    "plt.title('Teacher Cluster to Pupil Cluster Mapping')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "rule_scores_df = pd.read_csv(\"TeachFollowUp_Ruleset_Scores.csv\").drop(columns=['teaching_text'])\n",
    "\n",
    "\n",
    "\n",
    "ruleset_cols = ['Ruleset1', 'Ruleset2', 'Ruleset3', 'Ruleset4']\n",
    "\n",
    "# Normalize each row independently\n",
    "normalized_rules = rule_scores_df[ruleset_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()), axis=1)\n",
    "\n",
    "rule_scores_df[['Ruleset1_norm', 'Ruleset2_norm', 'Ruleset3_norm', 'Ruleset4_norm']] = normalized_rules\n",
    "\n",
    "rule_scores_df_cluster = rule_scores_df.merge(teacher_clusters, left_on='participant_id', right_on='participant_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pupil_teacher_relation.columns = ['pupil_id', 'teacher_id']\n",
    "\n",
    "learning_accuracy_df_Pupil_restructured.columns = ['pupil_id', 'hatched_acc_pupil', 'plain_acc_pupil', 'triangle_acc_pupil', 'cluster_pupil']\n",
    "learning_accuracy_df_restructured.columns = ['teacher_id', 'hatched_acc_teacher', 'plain_acc_teacher', 'triangle_acc_teacher', 'cluster_teacher']\n",
    "\n",
    "# Merge pupil and teacher data using pupil_teacher_relation as the mapping table\n",
    "# First merge pupil data with the relation table\n",
    "pupil_teacher_data = pupil_teacher_relation.merge(\n",
    "    learning_accuracy_df_Pupil_restructured,\n",
    "    on='pupil_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Then merge with teacher data\n",
    "combined_data = pupil_teacher_data.merge(\n",
    "    learning_accuracy_df_restructured,\n",
    "    on='teacher_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Now we have a dataframe with both pupil and teacher accuracy data\n",
    "print(\"Combined pupil-teacher accuracy data:\")\n",
    "(combined_data.head())\n",
    "\n",
    "# Create a figure to plot pupil-teacher accuracy connections\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Define trial types\n",
    "trial_types = ['plain', 'hatched', 'triangle']\n",
    "\n",
    "# Loop through each trial type\n",
    "for i, trial_type in enumerate(trial_types):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Extract pupil and teacher accuracies for this trial type\n",
    "    pupil_acc = combined_data[f'{trial_type}_acc_pupil']\n",
    "    teacher_acc = combined_data[f'{trial_type}_acc_teacher']\n",
    "\n",
    "    # Create scatter plot for teacher accuracies\n",
    "    teacher_scatter = ax.scatter(\n",
    "        np.ones(len(teacher_acc)) * 0.8,  # x-position for teacher points (now on left)\n",
    "        teacher_acc,\n",
    "        c=combined_data['cluster_teacher'].map({'Level0': 'blue', 'Level1': 'red', 'Level3': 'green'}),\n",
    "        label='Teacher',\n",
    "        alpha=0.7,\n",
    "        s=80,\n",
    "        marker='s'  # square markers for teachers\n",
    "    )\n",
    "    \n",
    "    # Create scatter plot for pupil accuracies\n",
    "    pupil_scatter = ax.scatter(\n",
    "        np.ones(len(pupil_acc)) * 1.2,  # x-position for pupil points (now on right)\n",
    "        pupil_acc,\n",
    "        c=combined_data['cluster_pupil'].map({'Level0': 'blue', 'Level1': 'red', 'Level3': 'green'}),\n",
    "        label='Pupil',\n",
    "        alpha=0.7,\n",
    "        s=80,\n",
    "        marker='o'\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    # Draw lines connecting pupil-teacher pairs\n",
    "    for j in range(len(combined_data)):\n",
    "        ax.plot(\n",
    "            [0.8, 1.2],  # x-coordinates for the line\n",
    "            [teacher_acc.iloc[j], pupil_acc.iloc[j]],  # y-coordinates for the line (teacher first, then pupil)\n",
    "            color='gray',\n",
    "            alpha=0.3,\n",
    "            linestyle='-',\n",
    "            linewidth=1\n",
    "        )\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f'{trial_type.capitalize()} Trials', fontsize=16)\n",
    "    ax.set_xlim(0.5, 1.5)\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.set_xticks([0.8, 1.2])\n",
    "    ax.set_xticklabels(['Teacher', 'Pupil'], fontsize=14)\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_ylabel('Accuracy', fontsize=14)\n",
    "    \n",
    "    # Add a legend for the clusters\n",
    "    if i == 2:\n",
    "        legend_elements = [\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Level 0'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Level 1'),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Level 3')\n",
    "        ]\n",
    "        ax.legend(handles=legend_elements, loc='upper right', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 3 panels (subplots) for the three trial types\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Define trial types and their positions in the plot\n",
    "trial_types = ['plain', 'hatched', 'triangle']\n",
    "\n",
    "# Loop through each trial type and create a plot\n",
    "for i, trial_type in enumerate(trial_types):\n",
    "    # Filter data for this trial type\n",
    "    teacher_data = testing_acc_Pupil_with_cluster[testing_acc_Pupil_with_cluster['trial_type_id'] == trial_type]\n",
    "    pupil_data = learning_acc_Pupil_with_cluster[learning_acc_Pupil_with_cluster['trial_type_id'] == trial_type]\n",
    "    \n",
    "    # Create box plots for both teacher and pupil data\n",
    "    sns.boxplot(x=['Pupil_wo_feedback']*len(teacher_data) + ['Pupil_w_feedback']*len(pupil_data),\n",
    "                y=pd.concat([teacher_data['accuracy'], pupil_data['accuracy']]),\n",
    "                ax=axes[i],\n",
    "                palette=['skyblue', 'lightgreen'],\n",
    "                width=0.5)\n",
    "    \n",
    "    # Add individual data points with jitter\n",
    "    sns.stripplot(x=['Pupil_wo_feedback']*len(teacher_data) + ['Pupil_w_feedback']*len(pupil_data),\n",
    "                  y=pd.concat([teacher_data['accuracy'], pupil_data['accuracy']]),\n",
    "                  ax=axes[i],\n",
    "                  size=4,\n",
    "                  alpha=0.6,\n",
    "                  jitter=True,\n",
    "                  hue=pd.concat([teacher_data['cluster'], pupil_data['cluster']]),\n",
    "                  palette={'Level0': 'blue', 'Level1': 'red', 'Level3': 'green'},\n",
    "                  dodge=False)\n",
    "    \n",
    "    # Set title and labels\n",
    "    axes[i].set_title(f'{trial_type.capitalize()} Trials', fontsize=14)\n",
    "    axes[i].set_xlabel('')\n",
    "    \n",
    "    # Only set y-label for the first subplot\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel('Accuracy', fontsize=12)\n",
    "    else:\n",
    "        axes[i].set_ylabel('')\n",
    "        \n",
    "    # Set y-axis limits\n",
    "    axes[i].set_ylim(0, 1.05)\n",
    "    \n",
    "    # Remove legend from all but the last subplot\n",
    "    if i < 2:\n",
    "        if axes[i].get_legend() is not None:\n",
    "            axes[i].get_legend().remove()\n",
    "\n",
    "# Adjust the legend position for the last subplot\n",
    "handles, labels = axes[2].get_legend_handles_labels()\n",
    "legend_labels = list(dict.fromkeys(labels))  # Remove duplicates\n",
    "legend_handles = [handles[labels.index(label)] for label in legend_labels]\n",
    "axes[2].legend(legend_handles, legend_labels, title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Comparison of pupil without vs with feedback Accuracy by Trial Type', fontsize=16, y=1.05)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching_explanation = pd.read_excel('./Teaching explanation annotation.xlsx')\n",
    "\n",
    "level0_ids = ~teaching_explanation['Level 1'] & ~teaching_explanation['Level 2'] & ~teaching_explanation['Level 3']\n",
    "level1_ids = teaching_explanation['Level 1'] & ~teaching_explanation['Level 2'] \n",
    "level2_ids = teaching_explanation['Level 1'] & teaching_explanation['Level 2'] & ~teaching_explanation['Level 3']\n",
    "level3_ids = teaching_explanation['Level 1'] & teaching_explanation['Level 2'] & teaching_explanation['Level 3']\n",
    "\n",
    "teaching_explanation['cluster_explanation'] = pd.Series(len(teaching_explanation))\n",
    "teaching_explanation.loc[level0_ids, 'cluster_explanation'] = 'Level0'\n",
    "teaching_explanation.loc[level1_ids, 'cluster_explanation'] = 'Level1'\n",
    "teaching_explanation.loc[level2_ids, 'cluster_explanation'] = 'Level2'\n",
    "teaching_explanation.loc[level3_ids, 'cluster_explanation'] = 'Level3'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# teaching_explanation['cluster'] = teaching_explanation['Level 1'] +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching_explanation[['participant_id', 'cluster_explanation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for each subplot\n",
    "datasets = [\n",
    "    [50, 50, 50],    # first panel\n",
    "    [100, 0, 100],   # second panel\n",
    "    [100, 100, 0],   # third panel\n",
    "    [100, 100, 100]  # fourth panel\n",
    "]\n",
    "\n",
    "labels = ['P', 'H', 'T']\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n",
    "\n",
    "for ax, values in zip(axes, datasets):\n",
    "    bars = ax.bar(x, values, color='navy')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_yticks(np.arange(0, 111, 20))\n",
    "    # add percentage labels on top of each bar\n",
    "    for bar, v in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, v + 2, f'{v}%', \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    # light grid lines for poster style\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.22)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
